# 바이브 코딩 12주 커리큘럼

> 연구원을 위한 실용 프로그래밍 강의

---

## 📋 강의 개요

### **목표**
반복 작업 자동화 도구를 직접 만들 수 있는 연구원

### **기간**
12주 (주 1회, 2시간)

### **구조**
- 1-6주: 기초 개념 + 실습
- 7-8주: 프로젝트 기획 + 심화 개념
- 9-12주: 개인 프로젝트 개발

### **핵심 철학**
- 코드 직접 작성 ❌
- AI에게 질문하는 법 ✅
- 개념 이해 + 도구 활용 ✅

---

## 📅 주차별 커리큘럼

### **Week 1: 기초 개념 + 환경 설정**

#### 주제
- 용어 사전
  - 프론트엔드/백엔드/API
  - 프레임워크/라이브러리
  - 기술 스택
- 프로그램 구조 이해
  - CLI (Command Line Interface)
  - GUI (Graphical User Interface)
  - Web Application
- CLI 기초 명령어
  - `cd` (디렉토리 이동)
  - `ls` / `dir` (목록 확인)
  - `python 파일명.py` (실행)

#### 시연 (40분)
1. 터미널 열기
2. 폴더 이동하기
3. Python 파일 실행하기
4. 가상환경 만들기 (`python -m venv venv`)
5. 패키지 설치하기 (`pip install pandas`)
6. 에러 발생 → 해결 과정 보여주기

#### 실습 (40분)
- Python 설치 확인 (`python --version`)
- VS Code 설치 및 터미널 열기
- 간단한 hello.py 파일 작성 및 실행
- pip로 패키지 설치해보기

#### 과제
터미널에서 Python 파일 실행 3번 연습

---

### **Week 2: AI 질문법 + Python 최소 개념**

#### 주제
- 좋은 질문 vs 나쁜 질문
  - 나쁜 예: "엑셀 처리 프로그램 만들어줘"
  - 좋은 예: "A.xlsx와 B.xlsx를 읽어서 날짜 컬럼 기준으로 병합 후 result.xlsx로 저장"
- 문제 쪼개기
  - 큰 문제 → 작은 단계들
  - 단계별로 AI에게 요청
- Python 최소 개념
  - 변수, 리스트, 딕셔너리 (읽을 줄만 알면 됨)
  - 함수 (호출 vs 정의)
  - 에러 메시지 읽는 법

#### 시연 (40분)
1. AI에게 "폴더의 모든 PDF 파일명을 list.txt에 저장" 요청
2. 받은 코드 저장하기
3. 터미널에서 실행하기
4. 일부러 에러 발생시키기
5. 에러 메시지 복사해서 AI에게 다시 질문
6. 수정된 코드로 재실행

#### 실습 (40분)
- AI에게 "특정 폴더의 모든 .txt 파일명 출력" 요청
- 코드 받아서 실행
- 에러 나면 메시지 복사 → AI에게 재질문
- 성공할 때까지 반복

#### 과제
AI에게 간단한 파일 처리 스크립트 3개 요청해보기

---

### **Week 3: 엑셀 처리 개념**

#### 주제
- pandas가 뭔가?
  - 엑셀 읽기/쓰기 가능
  - 데이터 필터, 정렬, 병합 가능
  - 그래프도 가능
  - "pandas 쓰면 엑셀 자동화"
- 내 엑셀 구조 파악하기
  - 어떤 시트? 어떤 컬럼?
  - 어떤 처리 필요?
  - AI에게 설명할 수 있게 준비
- 단계별로 쪼개서 요청하기

#### 시연 (40분)
목표: 여러 엑셀 파일 병합

1단계: "폴더의 모든 xlsx 파일명 출력"
→ 코드 받고 실행 → 확인

2단계: "그 파일들을 pandas로 읽어서 출력"
→ 코드 받고 실행 → 확인

3단계: "모두 병합해서 result.xlsx로 저장"
→ 완성

"한 번에 안 됩니다. 쪼개서 확인하세요."

#### 실습 (40분)
- 본인 엑셀 파일 준비 (실제 업무 데이터)
- 엑셀 구조 파악 (시트, 컬럼)
- AI에게 단계별로 요청
- 실행 → 확인 → 다음 단계

#### 과제
본인 업무의 엑셀 반복 작업 1개 자동화

---

### **Week 4: 크롤링 - 개발자 도구**

#### 주제
- HTML/CSS 최소 개념
  - 태그 구조 (`<div>`, `<p>`, `<a>`)
  - 클래스, id
  - "웹페이지 = 텍스트로 된 구조"
- 개발자 도구 (F12)
  - Elements 탭
  - selector 찾는 법
  - Copy selector
- 크롤링 도구 개념
  - requests (페이지 가져오기)
  - beautifulsoup (데이터 추출)
  - selenium (동적 페이지)

#### 시연 (40분)
1. 네이버 뉴스 페이지 접속
2. F12 눌러서 개발자 도구 열기
3. 제목 요소 찾기 (마우스로 선택)
4. selector 복사
5. AI에게: "이 페이지에서 [selector]의 텍스트를 추출해서 news.csv에 저장"
6. 코드 받아서 실행

#### 실습 (40분)
- 관심 사이트 접속 (특허청, 저널 등)
- F12로 원하는 데이터의 selector 찾기
- AI에게 크롤링 요청
- CSV 저장 확인

#### 과제
정기적으로 확인하는 사이트 1개 크롤러 만들기

---

### **Week 5: CLI → Streamlit (GUI의 편함)**

#### 주제
- CLI의 불편함
  - 터미널 실행
  - 파일 찾기
  - 결과 확인 번거로움
- Streamlit이 뭔가?
  - Python 코드 → 자동으로 웹 UI
  - 버튼, 입력창, 그래프 자동 생성
  - "웹 만들기 제일 쉬운 방법"
- Streamlit 구조
  - `st.file_uploader()` → 파일 받기
  - `st.button()` → 버튼
  - `st.write()` → 결과 표시

#### 시연 (40분)
같은 크롤러 두 버전:

**CLI 버전:**
```bash
python crawl.py naver.com
→ result.csv 생성
→ 파일 열어서 확인
```

**Streamlit 버전:**
```
브라우저 자동 열림
→ URL 입력창에 입력
→ 버튼 클릭
→ 화면에 표 바로 표시
→ 다운로드 버튼
```

"이게 더 편하죠? 웹이 이래서 좋아요."

#### 실습 (40분)
- Week 4 크롤러를 Streamlit으로 변환
- AI에게: "이 코드를 Streamlit으로 만들어줘"
- 실행: `streamlit run app.py`
- 브라우저에서 확인

#### 과제
본인 스크립트를 Streamlit으로 변환

---

### **Week 6: Streamlit 심화**

#### 주제
- 파일 업로드
  - `st.file_uploader()`
  - 여러 파일 동시 업로드
- 그래프 표시
  - `st.line_chart()`
  - `st.bar_chart()`
  - plotly 사용
- 결과 다운로드
  - 처리된 파일 다운로드 버튼
- 레이아웃
  - `st.columns()` (컬럼 나누기)
  - `st.sidebar` (사이드바)

#### 시연 (40분)
엑셀 처리 웹앱 만들기:
1. 파일 업로드 기능
2. 처리 버튼
3. 그래프 표시
4. 결과 다운로드

단계별로 기능 추가하는 과정 보여주기

#### 실습 (40분)
- 본인 프로젝트에 UI 추가
- 파일 업로드 기능
- 결과 시각화
- 다운로드 버튼

#### 과제
Streamlit 앱 완성도 높이기

---

### **Week 7: 프로젝트 기획**

#### 주제
- 개인 프로젝트 아이디어 발굴
  - "내가 반복하는 귀찮은 일은?"
  - 엑셀? 크롤링? 문서 처리?
- 워크시트 작성
  - 입력: 정확히 무엇?
  - 처리: 어떤 단계들?
  - 출력: 어떤 형식?
- 필요 도구 파악
  - pandas? requests? Streamlit?
  - AI API? 이메일?

#### 시연 (30분)
예시 프로젝트 기획:

**프로젝트: 논문 PDF 자동 정리**

입력:
- 폴더에 논문 PDF 50개
- 파일명이 불규칙

처리:
1. 각 PDF 첫 페이지 읽기
2. 제목 추출 (AI API)
3. 저자 추출
4. 년도 추출

출력:
- papers.xlsx (제목, 저자, 년도, 파일명)
- 파일명을 "제목_년도.pdf"로 변경

필요 도구:
- PyPDF2 (PDF 읽기)
- Claude API (제목 추출)
- pandas (엑셀 저장)
- Streamlit (UI)

#### 실습 (60분)
- 본인 프로젝트 구체화
- 워크시트 작성
- 1:1 피드백 및 조언

#### 과제
프로젝트 기획서 완성 (입력/처리/출력 명확히)

---

### **Week 8: Frontend 맛보기**

#### 주제
- Streamlit vs Frontend 비교
  - Streamlit: 빠름, 간단, 내부용
  - Frontend: 전문적, 복잡한 UI, 사용자 많을 때
- 언제 넘어가나? (체크리스트)
  - 사용자 50명 이상?
  - 모바일 지원 필요?
  - 복잡한 UI?
  - 실시간 반응 필요?
- Next.js + FastAPI 구조
  - Frontend: 화면
  - Backend: 데이터 처리
  - API: 둘 사이 소통

#### 시연 (30분)
같은 기능, 두 가지 구현 비교:

**Streamlit 버전:**
- 기본 파일 업로드 버튼
- 검색하면 전체 새로고침
- 단순 레이아웃

**Frontend 버전:**
- 드래그앤드롭
- 실시간 검색 (깜빡임 없음)
- 모달 팝업
- 부드러운 애니메이션

"차이 보이시죠?"

#### 실습 (60분)
- 본인 프로젝트 체크리스트 작성
  - Streamlit으로 충분?
  - Frontend 필요?
- 대부분은 Streamlit으로 충분
- 필요하면 나중에 전환 가능

#### 과제
프로젝트 개발 시작

---

### **Week 9-12: 개인 프로젝트**

#### Week 9: 핵심 기능 구현

**진행 (20분)**
- 각자 진행 상황 공유
- 막힌 부분 질문

**1:1 멘토링 (80분)**
- 각 10분씩
- 질문법 개선
- 에러 해결
- 방향 조언

#### Week 10: 기능 완성

**진행 (20분)**
- 중간 데모
- 서로 피드백

**1:1 멘토링 (80분)**
- 버그 수정
- 기능 추가
- UI 개선

#### Week 11: 테스트 및 마무리

**진행 (20분)**
- 거의 완성된 프로젝트 공유
- 최종 체크

**1:1 멘토링 (80분)**
- 마지막 버그 수정
- README 작성 도움
- 발표 준비

#### Week 12: 최종 발표

**발표 (각 10분)**
- 어떤 문제를 해결했나?
- 어떻게 만들었나?
- 시연
- 어려웠던 점과 해결 방법

**마무리 (30분)**
- 전체 회고
- 다음 학습 방향
- 커뮤니티 유지 방안

---

## ⏱️ 주간 시간 배분

### **Week 1-6 (기초)**
```
총 2시간:
- 주제 설명: 30분
- 시연: 40분
- 실습: 40분
- 질문: 10분
```

### **Week 7-8 (기획/심화)**
```
총 2시간:
- 주제: 20분
- 시연: 30분
- 실습: 60분
- 질문: 10분
```

### **Week 9-12 (프로젝트)**
```
총 2시간:
- 진행 상황 공유: 20분
- 1:1 멘토링: 80분 (각 10분)
- 질문 및 토론: 20분
```

---

## 🎯 학습 목표

### **단계별 목표**

```
Week 1-2: 기초 다지기
- AI 질문법 터득
- 터미널 사용 익숙해지기
- 에러 대응 방법 학습

Week 3-4: 도구 이해
- pandas 가능성 이해
- 크롤링 개념 파악
- selector 찾기 숙달

Week 5-6: GUI 만들기
- Streamlit으로 웹앱 제작
- 사용자 인터페이스 이해
- 실용적 도구 완성

Week 7-8: 확장 개념
- 프로젝트 기획 능력
- Frontend 개념 이해
- 도구 선택 판단력

Week 9-12: 실전 프로젝트
- 실제 사용 가능한 도구 완성
- 독립적 문제 해결 능력
- 지속적 학습 기반 마련
```

---

## 📝 과제 (선택 사항)

```
Week 1: 터미널에서 Python 파일 실행 3번
Week 2: AI에게 간단한 스크립트 3개 요청
Week 3: 본인 엑셀 처리 자동화 1개
Week 4: 관심 사이트 크롤러 1개
Week 5: 크롤러를 Streamlit으로 변환
Week 6: Streamlit 앱 완성도 높이기
Week 7: 프로젝트 기획서 작성
Week 9-12: 프로젝트 개발 진행
```

---

## 🎓 최종 결과물

### **각자 제출**

```
1. 실제 사용 가능한 도구 1개
   - Streamlit 웹앱 또는 CLI 스크립트

2. GitHub 저장소
   - 코드
   - README.md
   - 실행 방법 문서

3. 발표 자료
   - 문제 정의
   - 해결 방법
   - 시연
   - 배운 점
```

---

## 💡 강의 원칙

### **하지 않을 것**
- ❌ 코드 문법 강의
- ❌ 알고리즘 문제 풀이
- ❌ 컴퓨터 과학 이론

### **할 것**
- ✅ 개념 이해 (도구가 뭘 하는지)
- ✅ AI 질문법 (구체적으로 요청하기)
- ✅ 에러 대응 (포기하지 않기)
- ✅ 실용적 도구 만들기

---

## 📚 추천 학습 자료

### **공식 문서**
- Streamlit: https://docs.streamlit.io
- pandas: https://pandas.pydata.org/docs
- FastAPI: https://fastapi.tiangolo.com/ko

### **AI 도구**
- Claude (Anthropic)
- ChatGPT (OpenAI)
- Cursor (AI 코드 에디터)

### **커뮤니티**
- GitHub (코드 공유)
- Stack Overflow (에러 해결)

---

## 🔄 후속 학습 경로

### **바이브 코딩 이후**

```
Level 1 (현재): Streamlit 기반 도구
→ 연구원 대부분 여기서 충분

Level 2 (심화): Full Stack
→ React + FastAPI
→ 더 전문적인 웹 서비스

Level 3 (전문가): 특화 분야
→ AI/ML 엔지니어링
→ 데이터 사이언스
→ DevOps
```

---

## ✨ 성공 기준

```
이 강의를 성공적으로 마치면:

✅ 반복 작업을 자동화할 수 있다
✅ AI에게 효과적으로 질문할 수 있다
✅ 에러가 나도 포기하지 않는다
✅ 실제로 쓰는 도구를 만들었다
✅ 계속 학습할 수 있는 기반이 생겼다

가장 중요한 것:
"내가 필요한 걸 내가 만들 수 있다"는 자신감
```

---

**문의 및 피드백: [연락처]**